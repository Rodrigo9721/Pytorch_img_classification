{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6812a7",
   "metadata": {},
   "source": [
    "Monitorear el entrenamiento con tensorboard (tensorboard --logdir=runs) en el directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6550269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # Primera capa de convolución\n",
    "        self.conv1_bn = nn.BatchNorm2d(32) # Capa de normalización de lote luego de cada capa de convolución\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # Segunda capa de convolución\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f17af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Inicializar el escritor de TensorBoard\n",
    "    writer = SummaryWriter('runs/experiment_1')\n",
    "    # Cargar y normalizar los conjuntos de datos CIFAR10\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.RandomHorizontalFlip(),  # Aumento de datos con flip\n",
    "        transforms.RandomCrop(32, padding=4),  # Aumento de datos con crop\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "    train_size = int(0.8 * len(full_trainset))\n",
    "    test_size = len(full_trainset) - train_size\n",
    "    trainset, valset = torch.utils.data.random_split(full_trainset, [train_size, test_size])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                            shuffle=True, num_workers=4)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
    "                                            shuffle=True, num_workers=4)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                            shuffle=False, num_workers=4)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # Crear la red\n",
    "    net = Net()\n",
    "    # Mover el modelo a la GPU\n",
    "    net.to(device)\n",
    "    \n",
    "    # Definir la función de pérdida y el optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    # Cargar el último checkpoint si existe\n",
    "    start_epoch = 0\n",
    "    if os.path.exists('checkpoints/latest_checkpoint.pth'):\n",
    "        checkpoint = torch.load('checkpoints/latest_checkpoint.pth')\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        print(f'Loaded checkpoint from epoch {start_epoch}')\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting from scratch.\")\n",
    "\n",
    "    # Entrenar la red y guardar las pérdidas para la visualización\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    n_epochs_stop = 15\n",
    "\n",
    "    for epoch in range(start_epoch,20000):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            # move the inputs and labels to GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99 or i == len(trainloader) - 1:  # Asume que la indexación comienza en 0\n",
    "                avg_loss = running_loss / (i+1)\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, avg_loss))\n",
    "                train_losses.append(avg_loss)\n",
    "                writer.add_scalar('training loss', avg_loss, epoch * len(trainloader) + i)\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        avg_val_loss = val_loss / total\n",
    "        val_accuracy = correct / total\n",
    "        print(f'Validation loss: {avg_val_loss:.3f}, Validation accuracy: {val_accuracy:.3f}')\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        if epoch % 10 == 9:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss\n",
    "            }, f'checkpoints/checkpoint{epoch}.pth')\n",
    "            print(f'Saved checkpoint at epoch {epoch}')\n",
    "\n",
    "        # Guardar el último checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, 'checkpoints/latest_checkpoint.pth')\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(net.state_dict(), 'model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == n_epochs_stop:\n",
    "                print('Early stopping!')\n",
    "                # Load the best state dict\n",
    "                net.load_state_dict(torch.load('model.pth'))\n",
    "                # Exit the loop\n",
    "                break\n",
    "\n",
    "    print('Finished Training')\n",
    "    writer.close()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Visualizar la pérdida durante el entrenamiento\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Mini-batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluación del modelo en el conjunto de datos de prueba\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    torch.save(net.state_dict(), 'model.pth')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf893a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('model.pth'))\n",
    "net.to(device)\n",
    "net.eval()  # poner el modelo en modo de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y normalizar el conjunto de datos de prueba CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener algunas imágenes de prueba aleatorias\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "# Mostrar imágenes\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# Imprimir etiquetas verdaderas\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one2",
   "language": "python",
   "name": "one2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
